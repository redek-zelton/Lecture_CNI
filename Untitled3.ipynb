{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\antoi\\anaconda3\\lib\\site-packages (4.4.0.46)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\users\\antoi\\anaconda3\\lib\\site-packages (from opencv-python) (1.19.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(438, 606, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread(\"nette.png\")\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "HauteurImage=img.shape[0]\n",
    "LongueurImage= img.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('img',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preProcessing(img,LongueurImage,HauteurImage,iteration):\n",
    "    imgCopie=cv2.resize(img,(LongueurImage,HauteurImage))\n",
    "    gray = cv2.cvtColor(imgCopie, cv2.COLOR_BGR2RGB)\n",
    "    blured = cv2.GaussianBlur(gray,(5,5),cv2.BORDER_DEFAULT)######\n",
    "    imgCanny= cv2.Canny(blured, 30,15)\n",
    "    kernel = np.ones((5,5))\n",
    "    imgDial = cv2.dilate(imgCanny,kernel,iterations=iteration)\n",
    "    imgThres = cv2.erode(imgDial,kernel,iterations=1)\n",
    "    return imgThres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preProcessing(img,LongueurImage,HauteurImage,iteration):\n",
    "    imgCopie=cv2.resize(img,(LongueurImage,HauteurImage))\n",
    "    gray = cv2.cvtColor(imgCopie, cv2.COLOR_BGR2RGB)\n",
    "    blured = cv2.GaussianBlur(gray,(5,5),cv2.BORDER_DEFAULT)\n",
    "    imgCanny= cv2.Canny(blured, 80,100)\n",
    "    kernel = np.ones((5,5))\n",
    "    imgDial = cv2.dilate(imgCanny,kernel,iterations=iteration)\n",
    "    imgThres = cv2.erode(imgDial,kernel,iterations=1)\n",
    "    return imgThres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration=3\n",
    "imgP=preProcessing(img,LongueurImage,HauteurImage,iteration)\n",
    "cv2.imshow('img',imgP)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shape4(biggest):\n",
    "    biggest=biggest\n",
    "    L1=[]\n",
    "    L2=[]\n",
    "    if biggest.shape != (4,1,2):\n",
    "        for i in biggest:\n",
    "            L1.append(i[0][0])\n",
    "            L2.append(i[0][1])\n",
    "        biggest=np.array([[[min(L1),min(L2)]],[[min(L1),max(L2)]],[[max(L1),min(L2)]],[[max(L1),max(L2)]]],np.int32)\n",
    "    return biggest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prendre le contour de la carte\n",
    "def getContours(imgThres):\n",
    "    biggest=np.array([])\n",
    "    maxArea = 0\n",
    "    contours,hierarchy = cv2.findContours(imgThres,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if area>500:\n",
    "            cv2.drawContours(imgThres,cnt,-1,(120,120,120),3)\n",
    "            peri = cv2.arcLength(cnt,True)\n",
    "            approx = cv2.approxPolyDP(cnt,0.02*peri,True)\n",
    "            if area > maxArea and len(approx) in (4,5,6,7,8,9,10):\n",
    "                biggest = approx\n",
    "                maxArea = area\n",
    "    biggest=shape4(biggest)\n",
    "    return biggest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration = 2\n",
    "imgThres=preProcessing(img,LongueurImage,HauteurImage,iteration)\n",
    "getContours(imgThres)\n",
    "cv2.imshow(\"Image\",imgThres)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorder(myPoints):\n",
    "    myPoints = myPoints.reshape((4,2))\n",
    "    myPointNew=np.zeros((4,1,2),np.int32)\n",
    "    add=myPoints.sum(1)\n",
    "    myPointNew[0]= myPoints[np.argmin(add)]\n",
    "    myPointNew[3]= myPoints[np.argmax(add)]\n",
    "    diff=np.diff(myPoints,axis=1)\n",
    "    myPointNew[1]= myPoints[np.argmin(diff)]\n",
    "    myPointNew[2]= myPoints[np.argmax(diff)]\n",
    "    return myPointNew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(biggest):\n",
    "    L=[]\n",
    "    H=[]\n",
    "    for i in biggest:\n",
    "        L.append(i[0][0])\n",
    "        H.append(i[0][1])\n",
    "    return L,H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 0, 407, 402]\n",
      "[25, 604, 39, 605]\n"
     ]
    }
   ],
   "source": [
    "biggest= reorder(getContours(imgThres))\n",
    "biggest\n",
    "L,H = resize(biggest)\n",
    "print(H)\n",
    "print(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disV(biggest):\n",
    "    L,H = resize(biggest)\n",
    "    Vt1= np.sqrt((L[0]-L[2])**2+(H[0]-H[2])**2)\n",
    "    Vt2= np.sqrt((L[1]-L[3])**2+(H[1]-H[3])**2)\n",
    "    return int(max(Vt1,Vt2)+1)\n",
    "def disH(biggest):\n",
    "    L,H = resize(biggest)\n",
    "    ht1= np.sqrt((L[0]-L[1])**2+(H[0]-H[1])**2)\n",
    "    ht2= np.sqrt((L[2]-L[3])**2+(H[2]-H[3])**2)\n",
    "    return int(max(ht1,ht2)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "403\n",
      "580\n"
     ]
    }
   ],
   "source": [
    "V =disV(biggest)\n",
    "H =disH(biggest)\n",
    "print(V)\n",
    "print(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWarp(img,biggest):\n",
    "    global LongueurImage\n",
    "    global HauteurImage\n",
    "    imgCopie=cv2.resize(img,(LongueurImage,HauteurImage))\n",
    "    biggest = reorder(biggest)\n",
    "    H=disH(biggest)\n",
    "    V=disV(biggest)\n",
    "    pts1=np.float32(biggest)\n",
    "    pts2=np.float32([[0,0],[H,0],[0,V],[H,V]])\n",
    "    matrix = cv2.getPerspectiveTransform(pts1,pts2)\n",
    "    imgOutput = cv2.warpPerspective(imgCopie,matrix,(H,V))\n",
    "    return imgOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(401, 576, 3)"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HauteurImage=img.shape[0]\n",
    "LongueurImage= img.shape[1]\n",
    "imgThres=preProcessing(img,LongueurImage,HauteurImage,iteration)\n",
    "biggest=getContours(imgThres)\n",
    "imgWarped=getWarp(img,biggest)\n",
    "imgWarped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Image\",img)\n",
    "cv2.imshow(\"I\",imgWarped)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ch(imgWarped):\n",
    "    img=cv2.resize(imgWarped,(imgWarped.shape[1],imgWarped.shape[0]))\n",
    "    ret,thresh1 = cv.threshold(img,127,255,cv.THRESH_BINARY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"v\\nREPUBLIQUE FRANCAISE\\nCARTE NATIONALE D'IDENTITE N°: 98765235012 ‘Nationalité Frangaise\\nNom: MARTIN\\nNom d’usage: MARTIN\\nPrénom(s): CHARLES, JEAN, PIERRE\\nSexe: M Né(e) le: 61.03.1975\\na: PARIS (75)\\nTaille :1,70M\\nSignature\\ndu titulaire : Mey\\nIDFRAMARTINK <<< <<< <<< £££ £££ ££ ££ £56236\\n023654848646964CHARLES<<JEAN<5698611M3\\nEe\\n\\x0c\""
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_config = r'--oem 3 --psm 6'\n",
    "pytesseract.image_to_string(imgWarped, config=custom_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function threshold>"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ch(imgWarped):\n",
    "    img=cv2.resize(imgWarped,(imgWarped.shape[1],imgWarped.shape[0]))\n",
    "    for i in range(len(imgWarped)):\n",
    "        for j in range(len(imgWarped[0])):\n",
    "            #imgWarped[i][j]=ColorNoir(imgWarped[i][j][0],imgWarped[i][j][1],imgWarped[i][j][2])\n",
    "            for k in range(len(imgWarped[0][0])):\n",
    "                if img[i][j][k]<180:\n",
    "                    img[i][j][k]=0\n",
    "                else:\n",
    "                    img[i][j][k]=255\n",
    "    return img\n",
    "cv2.threshold # seuil otsu # threshold binairy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colorNoir(i):\n",
    "    cpt=0\n",
    "    img=cv2.resize(i,(i.shape[1],i.shape[0]))\n",
    "    for j in range(len(i)):\n",
    "        for k in range(len(i[0])):\n",
    "            if((img[j][k][0]==0 and img[j][k][2]==0) or (img[j][k][0]==0 and img[j][k][1]==0) or (img[j][k][1]==0 and img[j][k][2]==0)):\n",
    "                img[j][k][0]=0\n",
    "                img[j][k][1]=0 \n",
    "                img[j][k][2]=0\n",
    "            #if((img[j][k][0]==0 and img[j][k][1]==0 and img[j][k][2]==0) or (img[j][k][0]==255 and img[j][k][1]==0 and img[j][k][2]==0) or (img[j][k][0]==0 and img[j][k][1]==255 and img[j][k][2]==0)):\n",
    "            #    img[j][k][0]=0\n",
    "            #    img[j][k][1]=0\n",
    "            #    img[j][k][2]=0\n",
    "            else:\n",
    "                img[j][k][0]=255\n",
    "                img[j][k][1]=255\n",
    "                img[j][k][2]=255\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=ch(imgWarped)\n",
    "p=colorNoir(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('i',i)\n",
    "cv2.imshow('p',p)\n",
    "cv2.imshow('i2',imgWarped)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'re |\\nhae:\\non aC re\\n“0 Mi. et Madame Dupont-lez-Boiz\\nTal, 0324 768 $21\\n13, avenue des Grands Prés oe ety .\\n23000 Gutret vo gin an BE\\n\\x0c'"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_config = r'--oem 3 --psm 6'\n",
    "pytesseract.image_to_string(p, config=custom_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'By te 3\\n1°\". Ma ot Madame Dupont-los-Bois\\nTél: 0324 768 $21\\n13, avenue des Grands Prés ee eny\\n23000 Guéret ed\\n\\x0c'"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_config = r'--oem 3 --psm 6'\n",
    "pytesseract.image_to_string(i, config=custom_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2) )- i. ct Madame Dupont-lne Bote\\n\\nTél.: 0324 768 321\\n13, avenue des Grands Prés et sony\\n23000 Gulret OP Vad HS\\n\\x0c'"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_config = r'--oem 3 --psm 6'\n",
    "pytesseract.image_to_string(imgWarped, config=custom_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the_biggest_component: 596397\n",
      "average: 15652.615384615385\n",
      "a4_constant: 46685.16483516483\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.4.0) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-6sxsq0tp\\opencv\\modules\\imgcodecs\\src\\loadsave.cpp:738: error: (-215:Assertion failed) !_img.empty() in function 'cv::imwrite'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-6dae52bc6740>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTHRESH_BINARY_INV\u001b[0m \u001b[1;33m|\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTHRESH_OTSU\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;31m# save the the result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"pre.png\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.4.0) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-6sxsq0tp\\opencv\\modules\\imgcodecs\\src\\loadsave.cpp:738: error: (-215:Assertion failed) !_img.empty() in function 'cv::imwrite'\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import measure, morphology\n",
    "from skimage.color import label2rgb\n",
    "from skimage.measure import regionprops\n",
    "import numpy as np\n",
    "\n",
    "# read the input image\n",
    "img = cv2.imread('nettetest.jpg')\n",
    "img = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)[1]  # ensure binary\n",
    "\n",
    "# connected component analysis by scikit-learn framework\n",
    "blobs = img < np.mean(img)\n",
    "blobs_labels = measure.label(blobs, background=1)\n",
    "#image_label_overlay = label2rgb(blobs_labels, image=img)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "'''\n",
    "# plot the connected components (for debugging)\n",
    "ax.imshow(image_label_overlay)\n",
    "ax.set_axis_off()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "'''\n",
    "\n",
    "the_biggest_component = 0\n",
    "total_area = 0\n",
    "counter = 0\n",
    "average = 0.0\n",
    "for region in regionprops(blobs_labels):\n",
    "    if (region.area > 10):\n",
    "        total_area = total_area + region.area\n",
    "        counter = counter + 1\n",
    "    # print region.area # (for debugging)\n",
    "    # take regions with large enough areas\n",
    "    if (region.area >= 250):\n",
    "        if (region.area > the_biggest_component):\n",
    "            the_biggest_component = region.area\n",
    "\n",
    "average = (total_area/counter)\n",
    "print(\"the_biggest_component: \" + str(the_biggest_component))\n",
    "print(\"average: \" + str(average))\n",
    "\n",
    "# experimental-based ratio calculation, modify it for your cases\n",
    "# a4_constant is used as a threshold value to remove connected pixels\n",
    "# are smaller than a4_constant for A4 size scanned documents\n",
    "a4_constant = ((average/84.0)*250.0)+100\n",
    "print(\"a4_constant: \" + str(a4_constant))\n",
    "\n",
    "# remove the connected pixels are smaller than a4_constant\n",
    "b = morphology.remove_small_objects(blobs_labels, a4_constant)\n",
    "# save the the pre-version which is the image is labelled with colors\n",
    "# as considering connected components\n",
    "#plt.imsave('pre_version.png', b)\n",
    "\n",
    "# read the pre-version\n",
    "img = cv2.imread('pre_version.jpg', 0)\n",
    "# ensure binary\n",
    "img = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
    "# save the the result\n",
    "cv2.imwrite(\"pre.png\", img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
